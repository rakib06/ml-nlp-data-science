{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2D5E9eSEvYXE",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-97d71bbbcfdf>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-97d71bbbcfdf>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    pip install tensorflow_datasets\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "import tensorflow_datasets as tfds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "A-ECKcDiv6v0"
   },
   "outputs": [],
   "source": [
    "def get_batch_data():\n",
    "  \n",
    "  (train_data, test_data), info = tfds.load('imdb_reviews/subwords8k',\n",
    "                                          split=(tfds.Split.TRAIN, tfds.Split.TEST),\n",
    "                                          with_info=True, as_supervised=True)\n",
    "  encoder = info.features['text'].encoder \n",
    "  padded_shapes = ([None], ())\n",
    "  train_batches = train_data.shuffle(1000).padded_batch(10,\n",
    "                                                        padded_shapes=padded_shapes)\n",
    "  test_batches = test_data.shuffle(1000).padded_batch(10, \n",
    "                                                      padded_shapes=padded_shapes)\n",
    "  return train_batches, test_batches, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "quRdPJbcxYNw"
   },
   "outputs": [],
   "source": [
    "def get_model(encoder, embedding_dim=16):\n",
    "  embedding_dim =16\n",
    "  model = keras.Sequential([layers.Embedding(encoder.vocab_size,embedding_dim),\n",
    "                          layers.GlobalAveragePooling1D(),\n",
    "                          layers.Dense(1, activation='sigmoid')\n",
    "                          ])\n",
    "\n",
    "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "  return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kQm8Qc98ZQQk"
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "  history_dict = history.history\n",
    "  acc = history_dict['accuracy']\n",
    "  val_acc = history_dict['val_accuracy']\n",
    "  epochs = range(1, len(acc)+1)\n",
    "  print(type(epochs),epochs)\n",
    "  print(acc)\n",
    "  plt.figure(figsize=(12, 9))\n",
    "  plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "  plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "  plt.title('Training and validation accuracy')\n",
    "  plt.xlabel('Epochs')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.legend(loc='lower right')\n",
    "  plt.ylim((0.5, 1))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "99NcfmnSZeZY"
   },
   "outputs": [],
   "source": [
    "\n",
    "def retrieve_embeddings(model, encoder):\n",
    "  out_vectors = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
    "  out_metadata = io.open('meta.tsv', 'w', encoding='utf-8')\n",
    "  weights = model.layers[0].get_weights()[0] # at 0 -> embeddig layer\n",
    "  for num,word in enumerate(encoder.subwords):\n",
    "    vec = weights[num+1]\n",
    "    out_metadata.write(word + '\\n')\n",
    "    out_metadata.write('\\t'.join([str(x) for x in vec])+'\\n')\n",
    "  out_vectors.close()\n",
    "  out_metadata.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "e7E95c6N7VDz"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tfds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-28f2711b8a08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_batches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_batch_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m history = model.fit(train_batches, epochs=10, validation_data=test_batches,\n\u001b[0;32m      4\u001b[0m                     validation_steps=20)\n\u001b[0;32m      5\u001b[0m \u001b[0mplot_history\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-bf19b146e66a>\u001b[0m in \u001b[0;36mget_batch_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_batch_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m   (train_data, test_data), info = tfds.load('imdb_reviews/subwords8k',\n\u001b[0m\u001b[0;32m      4\u001b[0m                                           \u001b[0msplit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSplit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtfds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSplit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTEST\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                           with_info=True, as_supervised=True)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tfds' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "train_batches, test_batches, encoder = get_batch_data()\n",
    "model = get_model(encoder)\n",
    "history = model.fit(train_batches, epochs=10, validation_data=test_batches,\n",
    "                    validation_steps=20)\n",
    "plot_history(history)\n",
    "\n",
    "retrieve_embeddings(model, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ju6W232XZB8Q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TAGy-7aeZCeg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "nlp_tf_freecodecamp.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
